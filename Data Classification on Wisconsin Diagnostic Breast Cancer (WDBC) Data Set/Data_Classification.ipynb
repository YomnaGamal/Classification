{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data_Classification.ipynb","provenance":[],"collapsed_sections":["Iq_d79Tmdfla"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"XxVpdiwXgJS8"},"source":["import pandas as pd\r\n","import numpy as np\r\n","from google.colab import drive\r\n","from sklearn.model_selection import KFold,GridSearchCV\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn import model_selection\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.preprocessing import MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OZzod9S1YkUR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608633123563,"user_tz":-120,"elapsed":24844,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"78907b6f-8d86-4f4f-b033-cb4574c0a5d6"},"source":["drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SALYUMA0ffeu"},"source":["filename = \"/content/drive/My Drive/College/Data_Mining_Assignments/Classification/wdbc.data\" #Arsany\r\n","# filename = \"/content/drive/My Drive/7th Term Assignments, Sheets & Labs/Classification/wdbc.data\" #Yomna\r\n","# filename = \"/content/drive/My Drive/7th Term Assignments, Sheets & Labs/Classification/wdbc.data\" #kirellos"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lYFXWl0ddqYs"},"source":["# **Classifier**"]},{"cell_type":"code","metadata":{"id":"KaJbPoxuGHLx"},"source":["def classifier(P_train, y_train, P_test, y_test): \r\n","  tuned_parameters = [{'C': [0.01, 0.1, 1, 10, 100, 1000]}]\r\n","  scores = ['precision', 'recall', 'f1']\r\n","  logistic = LogisticRegression()\r\n","  for score in scores:\r\n","      print(\"# Tuning hyper-parameters for %s\" % score)\r\n","      clf = GridSearchCV(logistic, tuned_parameters, cv=5, scoring='%s_macro' % score)\r\n","      clf.fit(P_train, y_train)\r\n","      print(\"Best parameter \\\"C value\\\"  is \" + str(clf.best_params_))\r\n","      print()\r\n","      print(\"Grid scores for all C values :\")\r\n","      print()\r\n","      means = clf.cv_results_['mean_test_score']\r\n","      stds = clf.cv_results_['std_test_score']\r\n","      for mean, std, params in zip(means, stds, clf.cv_results_['params']):\r\n","          print(\"%0.3f (+/-%0.03f) for %r\"\r\n","                % (mean, std * 2, params))\r\n","      print()\r\n","      print(\"Evaluation:\")\r\n","      print()\r\n","      y_true, y_pred = y_test, clf.predict(P_test)\r\n","      print(classification_report(y_true, y_pred))\r\n","      print(\"_______________________________________________________________________________________\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iq_d79Tmdfla"},"source":["# **Preprocessing**\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UO2FrLIjdp0o","executionInfo":{"status":"ok","timestamp":1608634053914,"user_tz":-120,"elapsed":689,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"86840580-ee14-467f-c129-5bd114edd1ac"},"source":["# reading .data/.csv files\r\n","dataframe =  pd.read_csv(filename, header=None)\r\n","dataframe.drop(dataframe.columns[0], axis=1, inplace=True)\r\n","print(\"DataFrame is: \\n_____________\\n\\n\",dataframe)\r\n","data = dataframe.values\r\n","data = data.reshape((569,31))\r\n","print(\"\\n\\nData is: \\n________\\n\\n\",data)\r\n","\r\n","# split into inputs and outputs\r\n","x, yy = data[:,1:], data[:,0]\r\n","y = []\r\n","#let the malignint --> 1 and the benign --> 0 in y(output)\r\n","for i in yy:\r\n","  if i == 'M':\r\n","    y.append(1)\r\n","  else:\r\n","    y.append(0)\r\n","y = np.asarray(y)\r\n","y = y.reshape(-1, 1)\r\n","\r\n","print(\"\\n X is: \\n\",x)\r\n","print(\"\\n X.shape is:\\n\", x.shape)\r\n","print(\"\\n Y is: \\n\", y)\r\n","print(\"\\n Y.shape is:\\n\", y.shape)\r\n","\r\n","dataframe.drop(dataframe.columns[0], axis=1, inplace=True)\r\n","data = dataframe.values\r\n","data = data.reshape((569,30))\r\n","print(\"\\n\\nData is: \\n________\\n\\n\",data)\r\n","dataframe"],"execution_count":null,"outputs":[{"output_type":"stream","text":["DataFrame is: \n","_____________\n","\n","     1      2      3       4       5   ...       27      28      29      30       31\n","0    M  17.99  10.38  122.80  1001.0  ...  0.66560  0.7119  0.2654  0.4601  0.11890\n","1    M  20.57  17.77  132.90  1326.0  ...  0.18660  0.2416  0.1860  0.2750  0.08902\n","2    M  19.69  21.25  130.00  1203.0  ...  0.42450  0.4504  0.2430  0.3613  0.08758\n","3    M  11.42  20.38   77.58   386.1  ...  0.86630  0.6869  0.2575  0.6638  0.17300\n","4    M  20.29  14.34  135.10  1297.0  ...  0.20500  0.4000  0.1625  0.2364  0.07678\n","..  ..    ...    ...     ...     ...  ...      ...     ...     ...     ...      ...\n","564  M  21.56  22.39  142.00  1479.0  ...  0.21130  0.4107  0.2216  0.2060  0.07115\n","565  M  20.13  28.25  131.20  1261.0  ...  0.19220  0.3215  0.1628  0.2572  0.06637\n","566  M  16.60  28.08  108.30   858.1  ...  0.30940  0.3403  0.1418  0.2218  0.07820\n","567  M  20.60  29.33  140.10  1265.0  ...  0.86810  0.9387  0.2650  0.4087  0.12400\n","568  B   7.76  24.54   47.92   181.0  ...  0.06444  0.0000  0.0000  0.2871  0.07039\n","\n","[569 rows x 31 columns]\n","\n","\n","Data is: \n","________\n","\n"," [['M' 17.99 10.38 ... 0.2654 0.4601 0.1189]\n"," ['M' 20.57 17.77 ... 0.18600000000000003 0.275 0.08902]\n"," ['M' 19.69 21.25 ... 0.243 0.3613 0.08757999999999999]\n"," ...\n"," ['M' 16.6 28.08 ... 0.1418 0.2218 0.0782]\n"," ['M' 20.6 29.33 ... 0.265 0.4087 0.124]\n"," ['B' 7.76 24.54 ... 0.0 0.2871 0.07039]]\n","\n"," X is: \n"," [[17.99 10.38 122.8 ... 0.2654 0.4601 0.1189]\n"," [20.57 17.77 132.9 ... 0.18600000000000003 0.275 0.08902]\n"," [19.69 21.25 130.0 ... 0.243 0.3613 0.08757999999999999]\n"," ...\n"," [16.6 28.08 108.3 ... 0.1418 0.2218 0.0782]\n"," [20.6 29.33 140.1 ... 0.265 0.4087 0.124]\n"," [7.76 24.54 47.92 ... 0.0 0.2871 0.07039]]\n","\n"," X.shape is:\n"," (569, 30)\n","\n"," Y is: \n"," [[1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]]\n","\n"," Y.shape is:\n"," (569, 1)\n","\n","\n","Data is: \n","________\n","\n"," [[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n"," [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n"," [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n"," ...\n"," [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n"," [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n"," [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.30010</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>1.0950</td>\n","      <td>0.9053</td>\n","      <td>8.589</td>\n","      <td>153.40</td>\n","      <td>0.006399</td>\n","      <td>0.04904</td>\n","      <td>0.05373</td>\n","      <td>0.01587</td>\n","      <td>0.03003</td>\n","      <td>0.006193</td>\n","      <td>25.380</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.16220</td>\n","      <td>0.66560</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.08690</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3.398</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.990</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.12380</td>\n","      <td>0.18660</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.19740</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4.585</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.570</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.14440</td>\n","      <td>0.42450</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.24140</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1.1560</td>\n","      <td>3.445</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.910</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.20980</td>\n","      <td>0.86630</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.19800</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5.438</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.540</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.13740</td>\n","      <td>0.20500</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>21.56</td>\n","      <td>22.39</td>\n","      <td>142.00</td>\n","      <td>1479.0</td>\n","      <td>0.11100</td>\n","      <td>0.11590</td>\n","      <td>0.24390</td>\n","      <td>0.13890</td>\n","      <td>0.1726</td>\n","      <td>0.05623</td>\n","      <td>1.1760</td>\n","      <td>1.2560</td>\n","      <td>7.673</td>\n","      <td>158.70</td>\n","      <td>0.010300</td>\n","      <td>0.02891</td>\n","      <td>0.05198</td>\n","      <td>0.02454</td>\n","      <td>0.01114</td>\n","      <td>0.004239</td>\n","      <td>25.450</td>\n","      <td>26.40</td>\n","      <td>166.10</td>\n","      <td>2027.0</td>\n","      <td>0.14100</td>\n","      <td>0.21130</td>\n","      <td>0.4107</td>\n","      <td>0.2216</td>\n","      <td>0.2060</td>\n","      <td>0.07115</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>20.13</td>\n","      <td>28.25</td>\n","      <td>131.20</td>\n","      <td>1261.0</td>\n","      <td>0.09780</td>\n","      <td>0.10340</td>\n","      <td>0.14400</td>\n","      <td>0.09791</td>\n","      <td>0.1752</td>\n","      <td>0.05533</td>\n","      <td>0.7655</td>\n","      <td>2.4630</td>\n","      <td>5.203</td>\n","      <td>99.04</td>\n","      <td>0.005769</td>\n","      <td>0.02423</td>\n","      <td>0.03950</td>\n","      <td>0.01678</td>\n","      <td>0.01898</td>\n","      <td>0.002498</td>\n","      <td>23.690</td>\n","      <td>38.25</td>\n","      <td>155.00</td>\n","      <td>1731.0</td>\n","      <td>0.11660</td>\n","      <td>0.19220</td>\n","      <td>0.3215</td>\n","      <td>0.1628</td>\n","      <td>0.2572</td>\n","      <td>0.06637</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>16.60</td>\n","      <td>28.08</td>\n","      <td>108.30</td>\n","      <td>858.1</td>\n","      <td>0.08455</td>\n","      <td>0.10230</td>\n","      <td>0.09251</td>\n","      <td>0.05302</td>\n","      <td>0.1590</td>\n","      <td>0.05648</td>\n","      <td>0.4564</td>\n","      <td>1.0750</td>\n","      <td>3.425</td>\n","      <td>48.55</td>\n","      <td>0.005903</td>\n","      <td>0.03731</td>\n","      <td>0.04730</td>\n","      <td>0.01557</td>\n","      <td>0.01318</td>\n","      <td>0.003892</td>\n","      <td>18.980</td>\n","      <td>34.12</td>\n","      <td>126.70</td>\n","      <td>1124.0</td>\n","      <td>0.11390</td>\n","      <td>0.30940</td>\n","      <td>0.3403</td>\n","      <td>0.1418</td>\n","      <td>0.2218</td>\n","      <td>0.07820</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>20.60</td>\n","      <td>29.33</td>\n","      <td>140.10</td>\n","      <td>1265.0</td>\n","      <td>0.11780</td>\n","      <td>0.27700</td>\n","      <td>0.35140</td>\n","      <td>0.15200</td>\n","      <td>0.2397</td>\n","      <td>0.07016</td>\n","      <td>0.7260</td>\n","      <td>1.5950</td>\n","      <td>5.772</td>\n","      <td>86.22</td>\n","      <td>0.006522</td>\n","      <td>0.06158</td>\n","      <td>0.07117</td>\n","      <td>0.01664</td>\n","      <td>0.02324</td>\n","      <td>0.006185</td>\n","      <td>25.740</td>\n","      <td>39.42</td>\n","      <td>184.60</td>\n","      <td>1821.0</td>\n","      <td>0.16500</td>\n","      <td>0.86810</td>\n","      <td>0.9387</td>\n","      <td>0.2650</td>\n","      <td>0.4087</td>\n","      <td>0.12400</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>7.76</td>\n","      <td>24.54</td>\n","      <td>47.92</td>\n","      <td>181.0</td>\n","      <td>0.05263</td>\n","      <td>0.04362</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.1587</td>\n","      <td>0.05884</td>\n","      <td>0.3857</td>\n","      <td>1.4280</td>\n","      <td>2.548</td>\n","      <td>19.15</td>\n","      <td>0.007189</td>\n","      <td>0.00466</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.02676</td>\n","      <td>0.002783</td>\n","      <td>9.456</td>\n","      <td>30.37</td>\n","      <td>59.16</td>\n","      <td>268.6</td>\n","      <td>0.08996</td>\n","      <td>0.06444</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.2871</td>\n","      <td>0.07039</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 30 columns</p>\n","</div>"],"text/plain":["        2      3       4       5   ...      28      29      30       31\n","0    17.99  10.38  122.80  1001.0  ...  0.7119  0.2654  0.4601  0.11890\n","1    20.57  17.77  132.90  1326.0  ...  0.2416  0.1860  0.2750  0.08902\n","2    19.69  21.25  130.00  1203.0  ...  0.4504  0.2430  0.3613  0.08758\n","3    11.42  20.38   77.58   386.1  ...  0.6869  0.2575  0.6638  0.17300\n","4    20.29  14.34  135.10  1297.0  ...  0.4000  0.1625  0.2364  0.07678\n","..     ...    ...     ...     ...  ...     ...     ...     ...      ...\n","564  21.56  22.39  142.00  1479.0  ...  0.4107  0.2216  0.2060  0.07115\n","565  20.13  28.25  131.20  1261.0  ...  0.3215  0.1628  0.2572  0.06637\n","566  16.60  28.08  108.30   858.1  ...  0.3403  0.1418  0.2218  0.07820\n","567  20.60  29.33  140.10  1265.0  ...  0.9387  0.2650  0.4087  0.12400\n","568   7.76  24.54   47.92   181.0  ...  0.0000  0.0000  0.2871  0.07039\n","\n","[569 rows x 30 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUCq4cU5P6l9","executionInfo":{"status":"ok","timestamp":1608634061834,"user_tz":-120,"elapsed":550,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"15f3954f-893d-4842-8d52-7403a831bbae"},"source":["#split 80% train and 20%\r\n","X_train, X_test, y_train, y_test = train_test_split(x, y, train_size = 0.8 )\r\n","y_train = y_train.flatten()\r\n","y_test = y_test.flatten()\r\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(455, 30) (114, 30) (455,) (114,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1gomKKrG_mA","executionInfo":{"status":"ok","timestamp":1608634063959,"user_tz":-120,"elapsed":626,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"09568a82-a76a-4413-e971-17ba611b899b"},"source":["print(X_train)\r\n","print(y_train)\r\n","print(X_test)\r\n","print(y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[14.45 20.22 94.49 ... 0.1838 0.4753 0.1013]\n"," [14.58 21.53 97.41 ... 0.2701 0.4264 0.1275]\n"," [13.68 16.33 87.76 ... 0.08703999999999999 0.2806 0.07782]\n"," ...\n"," [16.11 18.05 105.1 ... 0.1216 0.2792 0.08158]\n"," [13.85 17.21 88.44 ... 0.051039999999999995 0.2364 0.07182000000000001]\n"," [12.8 17.46 83.05 ... 0.08296 0.1988 0.07053]]\n","[1 1 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0\n"," 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0\n"," 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 0\n"," 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n"," 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0\n"," 0 0 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1\n"," 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0\n"," 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1\n"," 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0\n"," 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0\n"," 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0\n"," 0 1 0 1 0 0 1 1 1 0 0]\n","[[28.11 18.47 188.5 ... 0.1595 0.1648 0.05525]\n"," [11.43 15.39 73.06 ... 0.08476 0.2676 0.06765]\n"," [11.22 19.86 71.94 ... 0.02022 0.3292 0.06522]\n"," ...\n"," [12.88 18.22 84.45 ... 0.1096 0.2582 0.08893]\n"," [16.84 19.46 108.4 ... 0.08436 0.2527 0.05972]\n"," [11.62 18.18 76.38 ... 0.1416 0.266 0.0927]]\n","[1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n"," 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0\n"," 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n"," 0 0 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JLUzgBxg83mk"},"source":["**feature normalization on data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"id":"bB1_uFtr882M","executionInfo":{"status":"ok","timestamp":1608633679642,"user_tz":-120,"elapsed":735,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"4aee4147-5466-4743-9078-da5e9c796925"},"source":["#min_max_normalization\r\n","norm = (dataframe - dataframe.min()) / (dataframe.max() - dataframe.min())* (1-0) + 0\r\n","norm"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.521037</td>\n","      <td>0.022658</td>\n","      <td>0.545989</td>\n","      <td>0.363733</td>\n","      <td>0.593753</td>\n","      <td>0.792037</td>\n","      <td>0.703140</td>\n","      <td>0.731113</td>\n","      <td>0.686364</td>\n","      <td>0.605518</td>\n","      <td>0.356147</td>\n","      <td>0.120469</td>\n","      <td>0.369034</td>\n","      <td>0.273811</td>\n","      <td>0.159296</td>\n","      <td>0.351398</td>\n","      <td>0.135682</td>\n","      <td>0.300625</td>\n","      <td>0.311645</td>\n","      <td>0.183042</td>\n","      <td>0.620776</td>\n","      <td>0.141525</td>\n","      <td>0.668310</td>\n","      <td>0.450698</td>\n","      <td>0.601136</td>\n","      <td>0.619292</td>\n","      <td>0.568610</td>\n","      <td>0.912027</td>\n","      <td>0.598462</td>\n","      <td>0.418864</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.643144</td>\n","      <td>0.272574</td>\n","      <td>0.615783</td>\n","      <td>0.501591</td>\n","      <td>0.289880</td>\n","      <td>0.181768</td>\n","      <td>0.203608</td>\n","      <td>0.348757</td>\n","      <td>0.379798</td>\n","      <td>0.141323</td>\n","      <td>0.156437</td>\n","      <td>0.082589</td>\n","      <td>0.124440</td>\n","      <td>0.125660</td>\n","      <td>0.119387</td>\n","      <td>0.081323</td>\n","      <td>0.046970</td>\n","      <td>0.253836</td>\n","      <td>0.084539</td>\n","      <td>0.091110</td>\n","      <td>0.606901</td>\n","      <td>0.303571</td>\n","      <td>0.539818</td>\n","      <td>0.435214</td>\n","      <td>0.347553</td>\n","      <td>0.154563</td>\n","      <td>0.192971</td>\n","      <td>0.639175</td>\n","      <td>0.233590</td>\n","      <td>0.222878</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.601496</td>\n","      <td>0.390260</td>\n","      <td>0.595743</td>\n","      <td>0.449417</td>\n","      <td>0.514309</td>\n","      <td>0.431017</td>\n","      <td>0.462512</td>\n","      <td>0.635686</td>\n","      <td>0.509596</td>\n","      <td>0.211247</td>\n","      <td>0.229622</td>\n","      <td>0.094303</td>\n","      <td>0.180370</td>\n","      <td>0.162922</td>\n","      <td>0.150831</td>\n","      <td>0.283955</td>\n","      <td>0.096768</td>\n","      <td>0.389847</td>\n","      <td>0.205690</td>\n","      <td>0.127006</td>\n","      <td>0.556386</td>\n","      <td>0.360075</td>\n","      <td>0.508442</td>\n","      <td>0.374508</td>\n","      <td>0.483590</td>\n","      <td>0.385375</td>\n","      <td>0.359744</td>\n","      <td>0.835052</td>\n","      <td>0.403706</td>\n","      <td>0.213433</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.210090</td>\n","      <td>0.360839</td>\n","      <td>0.233501</td>\n","      <td>0.102906</td>\n","      <td>0.811321</td>\n","      <td>0.811361</td>\n","      <td>0.565604</td>\n","      <td>0.522863</td>\n","      <td>0.776263</td>\n","      <td>1.000000</td>\n","      <td>0.139091</td>\n","      <td>0.175875</td>\n","      <td>0.126655</td>\n","      <td>0.038155</td>\n","      <td>0.251453</td>\n","      <td>0.543215</td>\n","      <td>0.142955</td>\n","      <td>0.353665</td>\n","      <td>0.728148</td>\n","      <td>0.287205</td>\n","      <td>0.248310</td>\n","      <td>0.385928</td>\n","      <td>0.241347</td>\n","      <td>0.094008</td>\n","      <td>0.915472</td>\n","      <td>0.814012</td>\n","      <td>0.548642</td>\n","      <td>0.884880</td>\n","      <td>1.000000</td>\n","      <td>0.773711</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.629893</td>\n","      <td>0.156578</td>\n","      <td>0.630986</td>\n","      <td>0.489290</td>\n","      <td>0.430351</td>\n","      <td>0.347893</td>\n","      <td>0.463918</td>\n","      <td>0.518390</td>\n","      <td>0.378283</td>\n","      <td>0.186816</td>\n","      <td>0.233822</td>\n","      <td>0.093065</td>\n","      <td>0.220563</td>\n","      <td>0.163688</td>\n","      <td>0.332359</td>\n","      <td>0.167918</td>\n","      <td>0.143636</td>\n","      <td>0.357075</td>\n","      <td>0.136179</td>\n","      <td>0.145800</td>\n","      <td>0.519744</td>\n","      <td>0.123934</td>\n","      <td>0.506948</td>\n","      <td>0.341575</td>\n","      <td>0.437364</td>\n","      <td>0.172415</td>\n","      <td>0.319489</td>\n","      <td>0.558419</td>\n","      <td>0.157500</td>\n","      <td>0.142595</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>0.690000</td>\n","      <td>0.428813</td>\n","      <td>0.678668</td>\n","      <td>0.566490</td>\n","      <td>0.526948</td>\n","      <td>0.296055</td>\n","      <td>0.571462</td>\n","      <td>0.690358</td>\n","      <td>0.336364</td>\n","      <td>0.132056</td>\n","      <td>0.385479</td>\n","      <td>0.197976</td>\n","      <td>0.325873</td>\n","      <td>0.283710</td>\n","      <td>0.291906</td>\n","      <td>0.200213</td>\n","      <td>0.131263</td>\n","      <td>0.464861</td>\n","      <td>0.045843</td>\n","      <td>0.115536</td>\n","      <td>0.623266</td>\n","      <td>0.383262</td>\n","      <td>0.576174</td>\n","      <td>0.452664</td>\n","      <td>0.461137</td>\n","      <td>0.178527</td>\n","      <td>0.328035</td>\n","      <td>0.761512</td>\n","      <td>0.097575</td>\n","      <td>0.105667</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>0.622320</td>\n","      <td>0.626987</td>\n","      <td>0.604036</td>\n","      <td>0.474019</td>\n","      <td>0.407782</td>\n","      <td>0.257714</td>\n","      <td>0.337395</td>\n","      <td>0.486630</td>\n","      <td>0.349495</td>\n","      <td>0.113100</td>\n","      <td>0.236828</td>\n","      <td>0.464728</td>\n","      <td>0.209490</td>\n","      <td>0.172279</td>\n","      <td>0.137879</td>\n","      <td>0.165064</td>\n","      <td>0.099747</td>\n","      <td>0.317863</td>\n","      <td>0.156160</td>\n","      <td>0.055387</td>\n","      <td>0.560655</td>\n","      <td>0.699094</td>\n","      <td>0.520892</td>\n","      <td>0.379915</td>\n","      <td>0.300007</td>\n","      <td>0.159997</td>\n","      <td>0.256789</td>\n","      <td>0.559450</td>\n","      <td>0.198502</td>\n","      <td>0.074315</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>0.455251</td>\n","      <td>0.621238</td>\n","      <td>0.445788</td>\n","      <td>0.303118</td>\n","      <td>0.288165</td>\n","      <td>0.254340</td>\n","      <td>0.216753</td>\n","      <td>0.263519</td>\n","      <td>0.267677</td>\n","      <td>0.137321</td>\n","      <td>0.124896</td>\n","      <td>0.157974</td>\n","      <td>0.125713</td>\n","      <td>0.077976</td>\n","      <td>0.142435</td>\n","      <td>0.263301</td>\n","      <td>0.119444</td>\n","      <td>0.294942</td>\n","      <td>0.074548</td>\n","      <td>0.103547</td>\n","      <td>0.393099</td>\n","      <td>0.589019</td>\n","      <td>0.379949</td>\n","      <td>0.230731</td>\n","      <td>0.282177</td>\n","      <td>0.273705</td>\n","      <td>0.271805</td>\n","      <td>0.487285</td>\n","      <td>0.128721</td>\n","      <td>0.151909</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>0.644564</td>\n","      <td>0.663510</td>\n","      <td>0.665538</td>\n","      <td>0.475716</td>\n","      <td>0.588336</td>\n","      <td>0.790197</td>\n","      <td>0.823336</td>\n","      <td>0.755467</td>\n","      <td>0.675253</td>\n","      <td>0.425442</td>\n","      <td>0.222524</td>\n","      <td>0.272896</td>\n","      <td>0.236300</td>\n","      <td>0.148335</td>\n","      <td>0.163477</td>\n","      <td>0.445579</td>\n","      <td>0.179722</td>\n","      <td>0.315211</td>\n","      <td>0.216103</td>\n","      <td>0.182766</td>\n","      <td>0.633582</td>\n","      <td>0.730277</td>\n","      <td>0.668310</td>\n","      <td>0.402035</td>\n","      <td>0.619626</td>\n","      <td>0.815758</td>\n","      <td>0.749760</td>\n","      <td>0.910653</td>\n","      <td>0.497142</td>\n","      <td>0.452315</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>0.036869</td>\n","      <td>0.501522</td>\n","      <td>0.028540</td>\n","      <td>0.015907</td>\n","      <td>0.000000</td>\n","      <td>0.074351</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.266162</td>\n","      <td>0.187026</td>\n","      <td>0.099294</td>\n","      <td>0.235988</td>\n","      <td>0.084390</td>\n","      <td>0.023063</td>\n","      <td>0.186151</td>\n","      <td>0.018085</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.265633</td>\n","      <td>0.065234</td>\n","      <td>0.054287</td>\n","      <td>0.489072</td>\n","      <td>0.043578</td>\n","      <td>0.020497</td>\n","      <td>0.124084</td>\n","      <td>0.036043</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.257441</td>\n","      <td>0.100682</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 30 columns</p>\n","</div>"],"text/plain":["           2         3         4   ...        29        30        31\n","0    0.521037  0.022658  0.545989  ...  0.912027  0.598462  0.418864\n","1    0.643144  0.272574  0.615783  ...  0.639175  0.233590  0.222878\n","2    0.601496  0.390260  0.595743  ...  0.835052  0.403706  0.213433\n","3    0.210090  0.360839  0.233501  ...  0.884880  1.000000  0.773711\n","4    0.629893  0.156578  0.630986  ...  0.558419  0.157500  0.142595\n","..        ...       ...       ...  ...       ...       ...       ...\n","564  0.690000  0.428813  0.678668  ...  0.761512  0.097575  0.105667\n","565  0.622320  0.626987  0.604036  ...  0.559450  0.198502  0.074315\n","566  0.455251  0.621238  0.445788  ...  0.487285  0.128721  0.151909\n","567  0.644564  0.663510  0.665538  ...  0.910653  0.497142  0.452315\n","568  0.036869  0.501522  0.028540  ...  0.000000  0.257441  0.100682\n","\n","[569 rows x 30 columns]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwNnLyKwN6WZ","executionInfo":{"status":"ok","timestamp":1608634072011,"user_tz":-120,"elapsed":645,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"f30b4bec-1d53-4773-bf4b-405b16ec615c"},"source":["scaler = MinMaxScaler()\r\n","scaler.fit(data)\r\n","scaled_data = scaler.transform(data)\r\n","scaled_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n","        0.41886396],\n","       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n","        0.22287813],\n","       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n","        0.21343303],\n","       ...,\n","       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n","        0.1519087 ],\n","       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n","        0.45231536],\n","       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n","        0.10068215]])"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"7--WKz87EPNw"},"source":["**Feature Normalization on Training and Testing sets**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ak6o1DiT-57","executionInfo":{"status":"ok","timestamp":1608634076626,"user_tz":-120,"elapsed":2395,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"ff436d44-9562-4799-ee2d-0df52dc3f479"},"source":["# FEATURE NORMALIZATION\r\n","scaler = MinMaxScaler()\r\n","normalized_X_train = scaler.fit_transform(X_train)\r\n","normalized_X_test = scaler.transform(X_test)\r\n","print(\"\\n normalized_X_train is:\\n____________________\\n\\n\", normalized_X_train)\r\n","print(\"\\n normalized_X_test is:\\n____________________\\n\\n\", normalized_X_test)\r\n","\r\n","#we do not need it because it is already 0 and 1 scaled\r\n","# y_train = scaler.fit_transform(y_train)\r\n","# y_test = scaler.transform(y_test)\r\n","# print(\"\\n y_train is:\\n__________\\n\\n\", y_train)\r\n","# print(\"\\n y_test is:\\n__________\\n\\n\", y_test)\r\n","\r\n","print(\"\\n\\nClassifier after normalization\\n______________________________\")\r\n","classifier(normalized_X_train, y_train, normalized_X_test, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," normalized_X_train is:\n","____________________\n","\n"," [[0.36542884 0.3554278  0.35427294 ... 0.63161512 0.628425   0.30342385]\n"," [0.37178923 0.39972946 0.37467682 ... 0.92817869 0.53203233 0.4752722 ]\n"," [0.32775576 0.22387555 0.30724617 ... 0.29910653 0.24462842 0.14941624]\n"," ...\n"," [0.44664612 0.28204261 0.42841171 ... 0.41786942 0.24186872 0.17407845]\n"," [0.33607319 0.25363544 0.31199776 ... 0.17539519 0.15750049 0.11006166]\n"," [0.28470082 0.26208996 0.27433443 ... 0.28508591 0.08338261 0.10160042]]\n","\n"," normalized_X_test is:\n","____________________\n","\n"," [[1.03375899 0.2962462  1.01118021 ... 0.54810997 0.01636113 0.00137741]\n"," [0.2176721  0.19208657 0.20452799 ... 0.29127148 0.21900256 0.08271022]\n"," [0.20739762 0.3432533  0.19670184 ... 0.06948454 0.34042973 0.06677161]\n"," ...\n"," [0.2886149  0.28779168 0.28411711 ... 0.3766323  0.20047309 0.22228781]\n"," [0.48236215 0.32972607 0.4514709  ... 0.28989691 0.18963138 0.03069658]\n"," [0.22696805 0.28643896 0.22772692 ... 0.48659794 0.21584861 0.24701561]]\n","\n","\n","Classifier after normalization\n","______________________________\n","# Tuning hyper-parameters for precision\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"stream","text":["Best parameter \"C value\"  is {'C': 100}\n","\n","Grid scores for all C values :\n","\n","0.849 (+/-0.022) for {'C': 0.01}\n","0.949 (+/-0.021) for {'C': 0.1}\n","0.970 (+/-0.019) for {'C': 1}\n","0.986 (+/-0.021) for {'C': 10}\n","0.987 (+/-0.022) for {'C': 100}\n","0.975 (+/-0.029) for {'C': 1000}\n","\n","Evaluation:\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.99      0.97        72\n","           1       0.97      0.93      0.95        42\n","\n","    accuracy                           0.96       114\n","   macro avg       0.97      0.96      0.96       114\n","weighted avg       0.97      0.96      0.96       114\n","\n","_______________________________________________________________________________________\n","# Tuning hyper-parameters for recall\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"stream","text":["Best parameter \"C value\"  is {'C': 100}\n","\n","Grid scores for all C values :\n","\n","0.635 (+/-0.073) for {'C': 0.01}\n","0.914 (+/-0.052) for {'C': 0.1}\n","0.955 (+/-0.017) for {'C': 1}\n","0.982 (+/-0.028) for {'C': 10}\n","0.985 (+/-0.025) for {'C': 100}\n","0.969 (+/-0.037) for {'C': 1000}\n","\n","Evaluation:\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.99      0.97        72\n","           1       0.97      0.93      0.95        42\n","\n","    accuracy                           0.96       114\n","   macro avg       0.97      0.96      0.96       114\n","weighted avg       0.97      0.96      0.96       114\n","\n","_______________________________________________________________________________________\n","# Tuning hyper-parameters for f1\n","Best parameter \"C value\"  is {'C': 100}\n","\n","Grid scores for all C values :\n","\n","0.621 (+/-0.100) for {'C': 0.01}\n","0.927 (+/-0.044) for {'C': 0.1}\n","0.962 (+/-0.018) for {'C': 1}\n","0.983 (+/-0.024) for {'C': 10}\n","0.986 (+/-0.023) for {'C': 100}\n","0.972 (+/-0.032) for {'C': 1000}\n","\n","Evaluation:\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.99      0.97        72\n","           1       0.97      0.93      0.95        42\n","\n","    accuracy                           0.96       114\n","   macro avg       0.97      0.96      0.96       114\n","weighted avg       0.97      0.96      0.96       114\n","\n","_______________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"SNkTSmZwQlVW"},"source":["#unused normalization\r\n","\r\n","# from sklearn.preprocessing import Normalizer\r\n","# # The normalize features to account for feature scaling\r\n","# # Instantiate \r\n","# norm = Normalizer()\r\n","# # Fit and Transform both training and testing sets\r\n","# X_train_norm = norm.fit_transform(X_train)\r\n","# X_test_norm = norm.transform(X_test)\r\n","# print(\"\\n X_train_norm is:\\n_______________\\n\\n\", X_train_norm)\r\n","# print(\"\\n X_test_norm is:\\n_______________\\n\\n\", X_test_norm)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3q-pbumY86e2"},"source":["**feature selection/projection**(PCA)"]},{"cell_type":"code","metadata":{"id":"jvoT6RMs89Q9"},"source":["# from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\r\n","# # from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\r\n","# # Create Decision Tree classifer object\r\n","# clf = DecisionTreeClassifier()\r\n","# # Train Decision Tree Classifer\r\n","# clf = clf.fit(normalized_X_train, y_train)\r\n","# #Predict the response for test dataset\r\n","# y_pred = clf.predict(normalized_X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImNiBRcoLnO6","executionInfo":{"status":"ok","timestamp":1608634085028,"user_tz":-120,"elapsed":722,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"b66e4515-5379-428e-b437-d0afd394fd1f"},"source":["#feature projection using PCA\r\n","\r\n","# PCA algorithm (alpha = 0.95)\r\n","def PCA(D, alpha):\r\n","  # Compute the mean vector\r\n","  mu = np.mean(D, axis = 0)\r\n","  print(\"\\n the mean is:\\n\", mu)\r\n","\r\n","  # center the data\r\n","  z = D - mu.T\r\n","  print(\"\\n the centered data is:\\n\",z)\r\n","\r\n","  # compute COV matrix\r\n","  COV = np.dot(z.T, z) / D.shape[0]\r\n","  print(\"\\n the covariance matrix is:\\n\",COV)\r\n","\r\n","  # find eigenvalues and eigenvectors\r\n","  values, vectors = np.linalg.eigh(COV)\r\n","  sorted_eig  = np.argsort(-values)\r\n","  values = values[sorted_eig]\r\n","  # values = np.diag(values)\r\n","  vectors = vectors[:, sorted_eig]\r\n","  print(\"\\n the eigenvalues are:\\n\", values)\r\n","  print(\"\\n the eigenvectors are:\\n\", vectors)\r\n","\r\n","  # fraction of total variance\r\n","  tot = np.sum(values)\r\n","  var_exp = [(i / tot) for i in (values)]\r\n","  # var_exp = np.diag(var_exp)\r\n","  print(\"\\n the fraction of total variances:\\n\", var_exp)\r\n","\r\n","  # calculate the cumulative sum\r\n","  fr = np.cumsum(var_exp)\r\n","  print(\"\\n the cumulative sum:\\n\",fr)\r\n","\r\n","  # choose dimentionality\r\n","  index = 0\r\n","  for i in range(len(fr)):\r\n","    if fr[i] >= alpha:\r\n","      # smallest r so that f(r) >= alpha\r\n","      item_value = fr[i]\r\n","      index = i\r\n","      break\r\n","  print(\"\\n item is:\\n\",item_value)\r\n","  print(\"\\n we take till index: \\n\", index)\r\n","\r\n","  # Compute projection matrix U\r\n","  U = vectors[:, :index]\r\n","  print(\"\\n the projection matrix is:\\n\",U)\r\n","\r\n","  return U\r\n","\r\n","U = PCA(normalized_X_train, 0.95)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," the mean is:\n"," [0.35018939 0.32110804 0.33726888 0.21659478 0.33593893 0.26035199\n"," 0.20796825 0.24392947 0.37936064 0.26611054 0.11935559 0.18750049\n"," 0.11678805 0.06115854 0.17993827 0.17535701 0.08079853 0.2258976\n"," 0.1773243  0.10050324 0.29631268 0.36062935 0.28259288 0.1696771\n"," 0.40236427 0.218707   0.23126611 0.39436644 0.26141542 0.18943034]\n","\n"," the centered data is:\n"," [[ 0.01523945  0.03431976  0.01700406 ...  0.23724868  0.36700957\n","   0.11399351]\n"," [ 0.02159984  0.07862141  0.03740794 ...  0.53381225  0.27061691\n","   0.28584186]\n"," [-0.02243363 -0.09723249 -0.03002271 ... -0.09525991 -0.016787\n","  -0.0400141 ]\n"," ...\n"," [ 0.09645673 -0.03906543  0.09114283 ...  0.02350297 -0.01954671\n","  -0.01535189]\n"," [-0.01411619 -0.0674726  -0.02527112 ... -0.21897125 -0.10391493\n","  -0.07936868]\n"," [-0.06548857 -0.05901809 -0.06293445 ... -0.10928053 -0.17803281\n","  -0.08782992]]\n","\n"," the covariance matrix is:\n"," [[ 2.82720123e-02  8.37558260e-03  2.78408060e-02  2.39439130e-02\n","   3.76687618e-03  1.41509496e-02  2.14306092e-02  2.64614498e-02\n","   4.08348620e-03 -7.47117291e-03  1.21733640e-02 -1.81365358e-03\n","   1.19337614e-02  9.71275626e-03 -3.28849293e-03  5.88259706e-03\n","   3.05363739e-03  8.23552378e-03 -1.73716945e-03 -1.88303888e-04\n","   2.72939051e-02  8.33335284e-03  2.64682289e-02  2.14102526e-02\n","   3.18749413e-03  1.09957474e-02  1.64525409e-02  2.83339880e-02\n","   3.72626715e-03  2.50618645e-04]\n"," [ 8.37558260e-03  2.11485227e-02  8.42325338e-03  7.15427904e-03\n","  -1.35242448e-04  5.90803114e-03  8.68490526e-03  8.76282570e-03\n","   1.81410312e-03 -1.53607034e-03  4.74617022e-03  6.61627847e-03\n","   4.90143167e-03  3.41814116e-03  3.27553414e-04  4.33395103e-03\n","   1.75901383e-03  3.29328856e-03  8.01885972e-04  9.23026605e-04\n","   8.88444690e-03  2.15080297e-02  8.82061332e-03  7.03648638e-03\n","   1.59853563e-03  6.29256650e-03  8.00591876e-03  1.01197537e-02\n","   2.08582010e-03  2.00930579e-03]\n"," [ 2.78408060e-02  8.42325338e-03  2.75403342e-02  2.36108071e-02\n","   4.61337298e-03  1.53410138e-02  2.23746132e-02  2.70285909e-02\n","   4.86562995e-03 -6.11452086e-03  1.22509459e-02 -1.54924160e-03\n","   1.21379075e-02  9.72069097e-03 -2.91577533e-03  6.83197233e-03\n","   3.44869990e-03  8.74260655e-03 -1.23009273e-03  4.02307972e-04\n","   2.69332227e-02  8.40760070e-03  2.62654213e-02  2.11456512e-02\n","   3.93421482e-03  1.19253424e-02  1.73316673e-02  2.89713957e-02\n","   4.19891486e-03  1.13864978e-03]\n"," [ 2.39439130e-02  7.15427904e-03  2.36108071e-02  2.07443119e-02\n","   3.40633147e-03  1.19705360e-02  1.85820868e-02  2.27038972e-02\n","   3.64067842e-03 -5.82105752e-03  1.11848393e-02 -1.03936853e-03\n","   1.09437882e-02  8.99165412e-03 -2.14274705e-03  5.12224815e-03\n","   2.72572545e-03  7.03402669e-03 -1.07990933e-03  7.60393518e-05\n","   2.33291879e-02  6.96380032e-03  2.26579240e-02  1.87783991e-02\n","   2.83713561e-03  8.98682766e-03  1.37870706e-02  2.37004729e-02\n","   2.96842855e-03  1.79811451e-04]\n"," [ 3.76687618e-03 -1.35242448e-04  4.61337298e-03  3.40633147e-03\n","   1.97351264e-02  1.52156896e-02  1.36806869e-02  1.48502294e-02\n","   1.12111613e-02  1.27288035e-02  4.64379259e-03  1.52976345e-03\n","   4.47972304e-03  2.74010542e-03  4.81095155e-03  6.39910609e-03\n","   2.70843829e-03  6.19679218e-03  3.29113079e-03  4.01479225e-03\n","   4.96112064e-03  1.39447321e-03  5.39448923e-03  3.93496874e-03\n","   1.75475840e-02  1.03161966e-02  1.10289845e-02  1.59678759e-02\n","   7.10095145e-03  8.86185805e-03]\n"," [ 1.41509496e-02  5.90803114e-03  1.53410138e-02  1.19705360e-02\n","   1.52156896e-02  2.60638575e-02  2.64932348e-02  2.58834577e-02\n","   1.38242413e-02  1.34403762e-02  8.99512927e-03  1.31025052e-03\n","   9.84245975e-03  6.14036303e-03  2.35607481e-03  1.66370718e-02\n","   7.19237978e-03  1.25469182e-02  5.13828042e-03  7.87169427e-03\n","   1.47522704e-02  6.68996554e-03  1.57419855e-02  1.13710369e-02\n","   1.36903507e-02  2.10485984e-02  2.32929144e-02  2.94972766e-02\n","   1.01852056e-02  1.31234471e-02]\n"," [ 2.14306092e-02  8.68490526e-03  2.23746132e-02  1.85820868e-02\n","   1.36806869e-02  2.64932348e-02  3.44104570e-02  3.28633777e-02\n","   1.33272144e-02  9.15013921e-03  1.27754228e-02  2.12668671e-03\n","   1.32294105e-02  9.19741858e-03  2.07201124e-03  1.74020865e-02\n","   9.83734098e-03  1.53879349e-02  4.24170962e-03  8.13154378e-03\n","   2.16500506e-02  9.36962963e-03  2.23106894e-02  1.71972416e-02\n","   1.24729280e-02  2.11475809e-02  2.88538473e-02  3.57914960e-02\n","   9.35874270e-03  1.11601516e-02]\n"," [ 2.64614498e-02  8.76282570e-03  2.70285909e-02  2.27038972e-02\n","   1.48502294e-02  2.58834577e-02  3.28633777e-02  3.64452190e-02\n","   1.28811549e-02  5.06476528e-03  1.44236493e-02  7.75994587e-04\n","   1.45010239e-02  1.05161826e-02  1.01284836e-03  1.37708433e-02\n","   6.90831737e-03  1.45039633e-02  2.70486559e-03  5.10760408e-03\n","   2.65876369e-02  9.42899568e-03  2.66314952e-02  2.09506358e-02\n","   1.33852520e-02  1.96476794e-02  2.60879738e-02  3.91554460e-02\n","   9.16961264e-03  8.58352275e-03]\n"," [ 4.08348620e-03  1.81410312e-03  4.86562995e-03  3.64067842e-03\n","   1.12111613e-02  1.38242413e-02  1.33272144e-02  1.28811549e-02\n","   2.00073870e-02  9.99657745e-03  5.19855216e-03  2.40065744e-03\n","   5.33253553e-03  2.97312061e-03  2.61360906e-03  8.22728666e-03\n","   3.75168225e-03  6.58214463e-03  7.75603531e-03  4.54435246e-03\n","   4.88245991e-03  2.28268889e-03  5.47429826e-03  3.82806815e-03\n","   8.94879302e-03  1.00333651e-02  1.08039333e-02  1.36544762e-02\n","   1.19467129e-02  7.27861318e-03]\n"," [-7.47117291e-03 -1.53607034e-03 -6.11452086e-03 -5.82105752e-03\n","   1.27288035e-02  1.34403762e-02  9.15013921e-03  5.06476528e-03\n","   9.99657745e-03  2.19923227e-02  2.89607347e-04  3.33795383e-03\n","   9.88506545e-04 -8.47237723e-04  5.60909461e-03  1.06184490e-02\n","   4.76424394e-03  5.69793691e-03  6.24356120e-03  9.22517860e-03\n","  -5.97749536e-03 -9.53888173e-04 -4.68561977e-03 -4.38835134e-03\n","   1.14321010e-02  1.00879911e-02  8.64055056e-03  5.98869462e-03\n","   6.22970866e-03  1.35801300e-02]\n"," [ 1.21733640e-02  4.74617022e-03  1.22509459e-02  1.11848393e-02\n","   4.64379259e-03  8.99512927e-03  1.27754228e-02  1.44236493e-02\n","   5.19855216e-03  2.89607347e-04  1.14725057e-02  2.97717043e-03\n","   1.09211670e-02  7.85392057e-03  1.87483640e-03  6.07698694e-03\n","   3.11636920e-03  7.16598522e-03  3.03399327e-03  2.59241910e-03\n","   1.31313310e-02  3.86564843e-03  1.28720456e-02  1.11866698e-02\n","   2.67627344e-03  5.25079495e-03  7.86038275e-03  1.32694581e-02\n","   1.88006077e-03  9.42816070e-04]\n"," [-1.81365358e-03  6.61627847e-03 -1.54924160e-03 -1.03936853e-03\n","   1.52976345e-03  1.31025052e-03  2.12668671e-03  7.75994587e-04\n","   2.40065744e-03  3.33795383e-03  2.97717043e-03  1.48301696e-02\n","   3.15618166e-03  1.17048012e-03  4.94653377e-03  4.43942390e-03\n","   2.07100544e-03  3.56912692e-03  6.47926310e-03  3.60469353e-03\n","  -2.10491349e-03  7.99899551e-03 -1.81068465e-03 -1.25208532e-03\n","  -1.11705365e-03 -1.25467750e-03 -1.09727286e-03 -2.90583725e-03\n","  -1.26145582e-03 -3.41591185e-04]\n"," [ 1.19337614e-02  4.90143167e-03  1.21379075e-02  1.09437882e-02\n","   4.47972304e-03  9.84245975e-03  1.32294105e-02  1.45010239e-02\n","   5.33253553e-03  9.88506545e-04  1.09211670e-02  3.15618166e-03\n","   1.11131436e-02  7.56810223e-03  1.69759616e-03  7.00096797e-03\n","   3.36504356e-03  7.76734701e-03  3.43403652e-03  2.75185993e-03\n","   1.26525437e-02  4.02362342e-03  1.27709546e-02  1.07574814e-02\n","   2.42169173e-03  6.14660721e-03  8.59644025e-03  1.37503056e-02\n","   2.09283518e-03  1.41915483e-03]\n"," [ 9.71275626e-03  3.41814116e-03  9.72069097e-03  8.99165412e-03\n","   2.74010542e-03  6.14036303e-03  9.19741858e-03  1.05161826e-02\n","   2.97312061e-03 -8.47237723e-04  7.85392057e-03  1.17048012e-03\n","   7.56810223e-03  6.01503169e-03  5.56740499e-04  3.71480221e-03\n","   1.88046203e-03  4.35786493e-03  1.06111437e-03  1.14375746e-03\n","   1.02529580e-02  2.97104037e-03  1.00562967e-02  8.92257677e-03\n","   1.73656406e-03  3.88608786e-03  5.92076175e-03  9.97415360e-03\n","   1.21463944e-03  4.20209052e-04]\n"," [-3.28849293e-03  3.27553414e-04 -2.91577533e-03 -2.14274705e-03\n","   4.81095155e-03  2.35607481e-03  2.07201124e-03  1.01284836e-03\n","   2.61360906e-03  5.60909461e-03  1.87483640e-03  4.94653377e-03\n","   1.69759616e-03  5.56740499e-04  1.04539026e-02  4.63327754e-03\n","   2.11686331e-03  4.14909224e-03  4.76410253e-03  3.86237736e-03\n","  -3.41457354e-03 -9.17003165e-04 -3.07922633e-03 -2.19364127e-03\n","   4.85616110e-03 -6.66825821e-04 -9.39360891e-04 -1.69828734e-03\n","  -1.09870573e-03  1.14905450e-03]\n"," [ 5.88259706e-03  4.33395103e-03  6.83197233e-03  5.12224815e-03\n","   6.39910609e-03  1.66370718e-02  1.74020865e-02  1.37708433e-02\n","   8.22728666e-03  1.06184490e-02  6.07698694e-03  4.43942390e-03\n","   7.00096797e-03  3.71480221e-03  4.63327754e-03  1.86570014e-02\n","   8.25436201e-03  1.23805107e-02  7.02910216e-03  1.00308232e-02\n","   5.64418471e-03  3.59535780e-03  6.75761839e-03  4.41298386e-03\n","   4.37454459e-03  1.41203054e-02  1.52100658e-02  1.53310086e-02\n","   4.85033289e-03  9.11338936e-03]\n"," [ 3.05363739e-03  1.75901383e-03  3.44869990e-03  2.72572545e-03\n","   2.70843829e-03  7.19237978e-03  9.83734098e-03  6.90831737e-03\n","   3.75168225e-03  4.76424394e-03  3.11636920e-03  2.07100544e-03\n","   3.36504356e-03  1.88046203e-03  2.11686331e-03  8.25436201e-03\n","   5.54091505e-03  7.10438894e-03  2.85912995e-03  5.33151365e-03\n","   2.86381401e-03  1.31844428e-03  3.31054060e-03  2.30212947e-03\n","   1.65923878e-03  5.50515639e-03  8.34355651e-03  7.64110691e-03\n","   1.71169638e-03  3.69177353e-03]\n"," [ 8.23552378e-03  3.29328856e-03  8.74260655e-03  7.03402669e-03\n","   6.19679218e-03  1.25469182e-02  1.53879349e-02  1.45039633e-02\n","   6.58214463e-03  5.69793691e-03  7.16598522e-03  3.56912692e-03\n","   7.76734701e-03  4.35786493e-03  4.14909224e-03  1.23805107e-02\n","   7.10438894e-03  1.45441243e-02  4.80687847e-03  7.02504294e-03\n","   7.66275631e-03  1.84758126e-03  8.21379992e-03  5.94031731e-03\n","   3.51589875e-03  8.19064920e-03  1.13476373e-02  1.63171540e-02\n","   2.10792794e-03  4.11392410e-03]\n"," [-1.73716945e-03  8.01885972e-04 -1.23009273e-03 -1.07990933e-03\n","   3.29113079e-03  5.13828042e-03  4.24170962e-03  2.70486559e-03\n","   7.75603531e-03  6.24356120e-03  3.03399327e-03  6.47926310e-03\n","   3.43403652e-03  1.06111437e-03  4.76410253e-03  7.02910216e-03\n","   2.85912995e-03  4.80687847e-03  1.41060886e-02  4.30937102e-03\n","  -2.08644922e-03 -5.92777440e-04 -1.50460195e-03 -1.45963188e-03\n","  -2.01579294e-04  1.78329093e-03  1.15433167e-03  9.92328725e-05\n","   5.97070448e-03  1.40413743e-03]\n"," [-1.88303888e-04  9.23026605e-04  4.02307972e-04  7.60393518e-05\n","   4.01479225e-03  7.87169427e-03  8.13154378e-03  5.10760408e-03\n","   4.54435246e-03  9.22517860e-03  2.59241910e-03  3.60469353e-03\n","   2.75185993e-03  1.14375746e-03  3.86237736e-03  1.00308232e-02\n","   5.33151365e-03  7.02504294e-03  4.30937102e-03  8.48972498e-03\n","  -1.76287269e-04  2.12556018e-04  3.96908564e-04 -9.19764579e-06\n","   2.39940154e-03  5.60556107e-03  6.30727780e-03  4.94528403e-03\n","   1.52507731e-03  6.38621668e-03]\n"," [ 2.72939051e-02  8.88444690e-03  2.69332227e-02  2.33291879e-02\n","   4.96112064e-03  1.47522704e-02  2.16500506e-02  2.65876369e-02\n","   4.88245991e-03 -5.97749536e-03  1.31313310e-02 -2.10491349e-03\n","   1.26525437e-02  1.02529580e-02 -3.41457354e-03  5.64418471e-03\n","   2.86381401e-03  7.66275631e-03 -2.08644922e-03 -1.76287269e-04\n","   2.80014350e-02  9.86745169e-03  2.70747637e-02  2.22762897e-02\n","   5.66095756e-03  1.24028492e-02  1.76066177e-02  2.96540390e-02\n","   5.25986653e-03  1.96476951e-03]\n"," [ 8.33335284e-03  2.15080297e-02  8.40760070e-03  6.96380032e-03\n","   1.39447321e-03  6.68996554e-03  9.36962963e-03  9.42899568e-03\n","   2.28268889e-03 -9.53888173e-04  3.86564843e-03  7.99899551e-03\n","   4.02362342e-03  2.97104037e-03 -9.17003165e-04  3.59535780e-03\n","   1.31844428e-03  1.84758126e-03 -5.92777440e-04  2.12556018e-04\n","   9.86745169e-03  2.64817802e-02  9.77040413e-03  7.65738705e-03\n","   5.60384380e-03  8.99585792e-03  1.07891704e-02  1.31827507e-02\n","   4.92633958e-03  4.32281311e-03]\n"," [ 2.64682289e-02  8.82061332e-03  2.62654213e-02  2.26579240e-02\n","   5.39448923e-03  1.57419855e-02  2.23106894e-02  2.66314952e-02\n","   5.47429826e-03 -4.68561977e-03  1.28720456e-02 -1.81068465e-03\n","   1.27709546e-02  1.00562967e-02 -3.07922633e-03  6.75761839e-03\n","   3.31054060e-03  8.21379992e-03 -1.50460195e-03  3.96908564e-04\n","   2.70747637e-02  9.77040413e-03  2.65145846e-02  2.15561450e-02\n","   5.95388372e-03  1.33307593e-02  1.84009173e-02  2.98661131e-02\n","   5.55908167e-03  2.75724033e-03]\n"," [ 2.14102526e-02  7.03648638e-03  2.11456512e-02  1.87783991e-02\n","   3.93496874e-03  1.13710369e-02  1.71972416e-02  2.09506358e-02\n","   3.82806815e-03 -4.38835134e-03  1.11866698e-02 -1.25208532e-03\n","   1.07574814e-02  8.92257677e-03 -2.19364127e-03  4.41298386e-03\n","   2.30212947e-03  5.94031731e-03 -1.45963188e-03 -9.19764579e-06\n","   2.22762897e-02  7.65738705e-03  2.15561450e-02  1.83132529e-02\n","   4.37747238e-03  9.27422365e-03  1.34924069e-02  2.27509719e-02\n","   3.74617814e-03  1.37104704e-03]\n"," [ 3.18749413e-03  1.59853563e-03  3.93421482e-03  2.83713561e-03\n","   1.75475840e-02  1.36903507e-02  1.24729280e-02  1.33852520e-02\n","   8.94879302e-03  1.14321010e-02  2.67627344e-03 -1.11705365e-03\n","   2.42169173e-03  1.73656406e-03  4.85616110e-03  4.37454459e-03\n","   1.65923878e-03  3.51589875e-03 -2.01579294e-04  2.39940154e-03\n","   5.66095756e-03  5.60384380e-03  5.95388372e-03  4.37747238e-03\n","   2.29652455e-02  1.26891495e-02  1.35357008e-02  1.86131489e-02\n","   9.11808027e-03  1.11243589e-02]\n"," [ 1.09957474e-02  6.29256650e-03  1.19253424e-02  8.98682766e-03\n","   1.03161966e-02  2.10485984e-02  2.11475809e-02  1.96476794e-02\n","   1.00333651e-02  1.00879911e-02  5.25079495e-03 -1.25467750e-03\n","   6.14660721e-03  3.88608786e-03 -6.66825821e-04  1.41203054e-02\n","   5.50515639e-03  8.19064920e-03  1.78329093e-03  5.60556107e-03\n","   1.24028492e-02  8.99585792e-03  1.33307593e-02  9.27422365e-03\n","   1.26891495e-02  2.25814830e-02  2.35770079e-02  2.70671179e-02\n","   1.12533257e-02  1.43917870e-02]\n"," [ 1.64525409e-02  8.00591876e-03  1.73316673e-02  1.37870706e-02\n","   1.10289845e-02  2.32929144e-02  2.88538473e-02  2.60879738e-02\n","   1.08039333e-02  8.64055056e-03  7.86038275e-03 -1.09727286e-03\n","   8.59644025e-03  5.92076175e-03 -9.39360891e-04  1.52100658e-02\n","   8.34355651e-03  1.13476373e-02  1.15433167e-03  6.30727780e-03\n","   1.76066177e-02  1.07891704e-02  1.84009173e-02  1.34924069e-02\n","   1.35357008e-02  2.35770079e-02  3.04766022e-02  3.38327553e-02\n","   1.12848522e-02  1.39946029e-02]\n"," [ 2.83339880e-02  1.01197537e-02  2.89713957e-02  2.37004729e-02\n","   1.59678759e-02  2.94972766e-02  3.57914960e-02  3.91554460e-02\n","   1.36544762e-02  5.98869462e-03  1.32694581e-02 -2.90583725e-03\n","   1.37503056e-02  9.97415360e-03 -1.69828734e-03  1.53310086e-02\n","   7.64110691e-03  1.63171540e-02  9.92328725e-05  4.94528403e-03\n","   2.96540390e-02  1.31827507e-02  2.98661131e-02  2.27509719e-02\n","   1.86131489e-02  2.70671179e-02  3.38327553e-02  5.02507221e-02\n","   1.37888794e-02  1.35211689e-02]\n"," [ 3.72626715e-03  2.08582010e-03  4.19891486e-03  2.96842855e-03\n","   7.10095145e-03  1.01852056e-02  9.35874270e-03  9.16961264e-03\n","   1.19467129e-02  6.22970866e-03  1.88006077e-03 -1.26145582e-03\n","   2.09283518e-03  1.21463944e-03 -1.09870573e-03  4.85033289e-03\n","   1.71169638e-03  2.10792794e-03  5.97070448e-03  1.52507731e-03\n","   5.25986653e-03  4.92633958e-03  5.55908167e-03  3.74617814e-03\n","   9.11808027e-03  1.12533257e-02  1.12848522e-02  1.37888794e-02\n","   1.42098506e-02  7.83748613e-03]\n"," [ 2.50618645e-04  2.00930579e-03  1.13864978e-03  1.79811451e-04\n","   8.86185805e-03  1.31234471e-02  1.11601516e-02  8.58352275e-03\n","   7.27861318e-03  1.35801300e-02  9.42816070e-04 -3.41591185e-04\n","   1.41915483e-03  4.20209052e-04  1.14905450e-03  9.11338936e-03\n","   3.69177353e-03  4.11392410e-03  1.40413743e-03  6.38621668e-03\n","   1.96476951e-03  4.32281311e-03  2.75724033e-03  1.37104704e-03\n","   1.11243589e-02  1.43917870e-02  1.39946029e-02  1.35211689e-02\n","   7.83748613e-03  1.41099288e-02]]\n","\n"," the eigenvalues are:\n"," [3.34608796e-01 1.05002692e-01 4.39355403e-02 4.05340873e-02\n"," 2.62045144e-02 1.94674075e-02 9.81938415e-03 7.43695657e-03\n"," 6.73610731e-03 5.95907537e-03 5.45509103e-03 4.61842525e-03\n"," 4.17992641e-03 2.95678028e-03 1.54896965e-03 1.44901604e-03\n"," 9.34727608e-04 9.21793526e-04 7.84874626e-04 5.89335393e-04\n"," 5.71551791e-04 5.15660683e-04 3.29982745e-04 3.09176118e-04\n"," 2.66091373e-04 1.90779770e-04 1.04192599e-04 3.72145984e-05\n"," 1.51521637e-05 3.74073776e-06]\n","\n"," the eigenvectors are:\n"," [[-2.41851937e-01  2.70653449e-01  4.75474395e-02 -5.48239712e-02\n","   9.25795485e-03 -2.08998201e-02  3.34221197e-02 -5.01874316e-02\n","   1.70487994e-01 -2.04271110e-01 -4.00632197e-02  1.51278087e-01\n","   5.45014904e-02 -9.92251203e-02 -1.63498265e-01  2.70769035e-02\n","   4.94323622e-02  2.02546565e-01  1.55438713e-01 -1.26368896e-01\n","  -1.47154734e-01 -1.06669869e-01 -4.49700345e-02 -1.66114996e-01\n","  -5.17052352e-02 -8.43839071e-02  1.43578834e-01  1.79756771e-01\n","   1.87069956e-01  6.92315462e-01]\n"," [-1.00106853e-01  6.70947377e-02 -5.48417835e-01  2.37597187e-01\n","   2.34996616e-02  2.86496334e-02  1.14146219e-02 -6.53118295e-02\n","  -2.17331564e-01 -3.47828889e-01 -4.16751580e-02 -2.91960848e-01\n","   3.39829943e-03  1.42516447e-02 -2.47248536e-01 -1.61755449e-01\n","   1.92168615e-01 -5.89193590e-02  1.66987988e-01  4.44325335e-01\n","  -1.41510381e-02 -7.60492213e-02  2.07160214e-02  6.81913317e-02\n","  -3.77421197e-02  2.26352278e-02  3.07572530e-02 -1.06829746e-02\n","  -4.00230835e-03  5.67277314e-05]\n"," [-2.47161360e-01  2.42223300e-01  4.41503410e-02 -5.88361688e-02\n","   3.49397309e-03 -1.85775402e-02  2.30952916e-02 -6.59039166e-02\n","   1.71837984e-01 -2.03268374e-01 -4.43847629e-02  1.18010400e-01\n","   2.09499296e-02 -7.09795668e-02 -1.30351840e-01  5.38791636e-02\n","   7.15859682e-02  2.23994653e-01  1.39979448e-01 -1.36644343e-01\n","  -1.55356557e-01 -5.81052119e-02 -3.31549729e-02 -3.27644640e-02\n","  -2.81317027e-02 -5.03665137e-02  1.62943307e-01  6.75911164e-02\n","   3.33073893e-01 -6.99174937e-01]\n"," [-2.07163436e-01  2.29192811e-01  2.88524539e-02 -7.71652887e-02\n","   4.23136571e-02  3.31815978e-04 -5.55779028e-02 -1.57144568e-02\n","   1.15601730e-01 -1.12564501e-01 -9.88148420e-02  8.35250700e-02\n","   9.94160145e-02 -3.13982227e-02 -9.84219778e-02  4.27178138e-02\n","  -2.97640759e-02  1.44564693e-02  3.86227208e-01 -9.20368945e-02\n","  -2.95131526e-02  2.35096513e-01  8.24972872e-03  3.69121990e-02\n","   1.65933307e-01  9.29170764e-02 -5.49944750e-01 -2.37009267e-01\n","  -4.63970327e-01 -3.35642560e-02]\n"," [-1.23867832e-01 -2.38364092e-01  1.47651938e-01  2.98631272e-02\n","   4.35120786e-01  2.18298989e-01  4.76044257e-02 -1.97494914e-01\n","   9.17017793e-02 -5.91166424e-02  1.07560555e-01 -1.11777477e-01\n","  -2.36632602e-01 -4.77737584e-01 -2.54509094e-01 -2.06140089e-01\n","  -3.54098644e-01 -2.11199766e-01 -2.61272884e-02 -4.11167625e-02\n","  -9.45162791e-02 -3.03325985e-02 -8.36355080e-02  9.42701395e-02\n","  -2.54949504e-02 -1.67884108e-02 -1.72760141e-02  4.98178445e-03\n","  -1.34605739e-03 -8.40693959e-03]\n"," [-2.41742153e-01 -2.05497205e-01  3.07992486e-02 -4.02426933e-02\n","  -5.07962254e-02 -4.66908516e-04 -1.00519318e-01 -1.75250368e-01\n","   1.43552343e-01 -2.67254998e-01  9.05770516e-02 -1.17252537e-01\n","  -3.21541000e-01  9.58814227e-02  1.37203977e-01  2.92102123e-01\n","   1.04560212e-01  2.02201976e-01 -3.66303084e-01  1.10667168e-01\n","  -2.77664554e-01  2.56776279e-01  3.26843949e-01  3.47198466e-02\n","  -1.65367181e-01  1.57747645e-01 -1.32504091e-01 -3.38705875e-03\n","  -3.23294001e-02  4.99858419e-02]\n"," [-2.99956305e-01 -9.86520273e-02 -1.63553857e-02 -1.11114133e-01\n","  -1.16005523e-01  6.31619189e-02  1.39552942e-01 -2.32639102e-01\n","   4.55758258e-02  1.95956486e-01 -4.05019785e-01 -2.78901146e-01\n","   8.41057357e-02  2.00486588e-02  2.17928288e-01 -1.27946048e-03\n","  -4.80574615e-02  1.39565258e-01 -1.97410938e-02  1.02230975e-01\n","   7.05839684e-02  1.71184765e-01 -3.75115046e-01  1.93114047e-01\n","  -1.64967731e-01 -4.28949103e-01 -3.88165896e-02  3.50358473e-02\n","  -3.25244285e-03  2.20989628e-02]\n"," [-3.18644522e-01  1.11526089e-02  6.40975017e-02 -8.24032843e-02\n","   1.00248480e-01  7.12045665e-02  1.71354386e-01 -2.32879144e-01\n","   1.08668438e-01 -4.73521510e-02  1.02460839e-02 -1.69060895e-01\n","   5.29318831e-02  2.58537075e-01  3.06723000e-01 -3.54061437e-01\n","  -1.33331643e-01  1.04097381e-01  1.80385710e-02 -9.75709236e-03\n","   3.62484949e-01 -2.16839105e-01  2.06704772e-01 -1.64003149e-01\n","   2.35910487e-01  3.37015159e-01  1.01064599e-01 -1.79104284e-02\n","  -8.21806562e-03  5.81514936e-04]\n"," [-1.18655912e-01 -2.11394959e-01  1.50856721e-02 -7.80758081e-02\n","   2.85537590e-01 -5.09229978e-01  7.92699113e-02 -3.34263575e-01\n","  -4.27557350e-01 -7.88399338e-02 -2.08968030e-01  3.63236133e-01\n","  -9.42091570e-02  1.18977522e-01 -9.42915078e-02 -8.16872489e-04\n","   1.77188713e-01 -1.16321435e-01 -3.54462753e-02 -1.36364004e-01\n","   8.80538206e-02  4.89588472e-02 -5.74261953e-02 -3.18483173e-02\n","  -1.45731213e-04  6.13270835e-03  8.72388057e-03  6.34551010e-03\n","  -9.95316138e-03 -1.17560058e-03]\n"," [-4.87010926e-02 -4.09459391e-01  9.60035526e-03 -4.81138878e-02\n","   2.43867496e-02  1.12206758e-01 -3.86244590e-01 -2.38761767e-01\n","   5.39795791e-02 -1.19314809e-01  1.22936810e-01 -1.30387052e-01\n","   3.90181359e-01  1.56237160e-01 -1.41400311e-02  4.15926522e-01\n","  -2.82295364e-02 -1.85686958e-01  2.45430515e-01 -6.03968202e-02\n","  -3.40486117e-02 -2.18702585e-01 -3.27025963e-02 -1.39191383e-01\n","   1.31564792e-01 -1.20782162e-01  9.13711151e-02 -1.30353346e-02\n","   5.46491330e-03 -6.01322538e-03]\n"," [-1.32414383e-01  6.74495724e-02 -7.80288556e-02 -2.23106433e-01\n","   1.65000962e-01  2.82159869e-02 -2.91391466e-01  1.30043147e-01\n","  -2.62533746e-01  2.37741553e-01  5.30895971e-02 -1.34905276e-01\n","  -9.63917565e-02  1.46139765e-02  2.46467731e-02 -1.91560346e-01\n","   1.79977029e-02  1.22572451e-01 -8.97096591e-02  2.08563609e-02\n","  -1.70665876e-01 -1.58189940e-01  3.54210821e-02 -5.25089835e-01\n","  -1.19260500e-01 -2.20719818e-01 -2.75283504e-01 -2.79177866e-01\n","   1.64014134e-01 -2.05369480e-02]\n"," [-5.51292527e-03 -7.12463919e-02 -4.33018458e-01 -1.77512576e-01\n","   1.82514607e-01  6.98438672e-02  6.11073241e-02 -1.88088546e-01\n","   4.33559938e-01  4.50847037e-01  1.40699672e-01  4.13829506e-01\n","  -6.75724751e-02  1.24119313e-01 -6.76578494e-02  2.80893126e-02\n","   6.62173078e-02  2.29684137e-03  7.85914151e-02  2.72365647e-01\n","  -3.45932311e-02 -1.29876092e-02  3.42096784e-02  2.81357791e-02\n","  -4.49090144e-02  1.44363230e-02  2.09237680e-02 -1.43246730e-02\n","  -2.07632290e-03 -6.67242415e-04]\n"," [-1.34861705e-01  5.20810415e-02 -8.79142306e-02 -2.23578504e-01\n","   1.16380765e-01  1.15687369e-02 -2.70173488e-01  1.17067296e-01\n","  -2.27142763e-01  2.17577036e-01  1.20477188e-01 -1.65601714e-01\n","  -1.78775631e-01  8.06272715e-02 -3.31225149e-02  6.19752284e-02\n","   7.59532950e-02  2.18393129e-01  5.63700497e-02 -1.63147524e-01\n","  -7.26625587e-02 -2.50901382e-01 -1.74846635e-01  4.70344318e-01\n","   1.57684600e-01  2.36998844e-01 -9.25302715e-02  3.77492552e-01\n","  -2.72704218e-02  2.47057757e-02]\n"," [-9.77518660e-02  7.52996544e-02 -3.31748830e-02 -1.26992223e-01\n","   9.78619223e-02  2.41634681e-02 -2.31763435e-01  8.50523751e-02\n","  -1.63726752e-01  1.55466650e-01 -2.41119479e-02 -9.07595294e-02\n","  -7.20227949e-02  5.13284616e-03  7.51909168e-02 -8.00551324e-02\n","  -8.38589302e-02 -3.74349909e-02  2.97538209e-01 -5.60195572e-02\n","  -1.21590878e-01  5.00468103e-01  2.07829354e-01 -1.75904886e-02\n","  -2.87320794e-02  1.43763627e-02  6.12704831e-01 -5.02027811e-02\n","  -1.77268829e-01  1.12602638e-02]\n"," [-1.31270565e-03 -1.34192899e-01 -1.12574475e-01 -2.05951536e-01\n","   2.19079278e-01  2.67939452e-01  1.60762790e-01  4.26376809e-01\n","  -1.50974984e-02 -2.44739739e-01 -3.97060545e-01  1.44984805e-01\n","   3.72849277e-02  4.30054146e-01 -1.20140555e-01  4.34147165e-02\n","  -3.21611615e-01 -6.23477465e-02 -1.26810734e-01 -2.53854180e-02\n","  -1.74787673e-01 -4.05103338e-02 -3.74620568e-03  3.04248224e-02\n","   8.61785275e-04  1.04764395e-02  2.23568996e-02  1.47238267e-02\n","   2.29610232e-03 -1.82182148e-03]\n"," [-1.40212984e-01 -2.05328613e-01 -1.50356803e-01 -2.41213736e-01\n","  -3.09510155e-01  1.21389086e-02 -4.05274982e-02  2.06865229e-01\n","   2.00411769e-02 -2.17238818e-01 -9.56928215e-03  1.97292102e-01\n","  -3.22150520e-01 -2.12085106e-01  3.56525662e-01 -7.04904625e-02\n","   3.65555160e-02 -2.75361464e-01  3.15591335e-01 -9.78156515e-02\n","   1.42445712e-01 -2.28305490e-01  4.66668869e-02  6.47620191e-02\n","  -2.85336814e-01 -3.45435624e-02 -3.34806170e-02 -2.23730843e-02\n","   1.46518358e-02 -6.22196027e-04]\n"," [-6.90262379e-02 -9.02731190e-02 -6.70459336e-02 -1.45289223e-01\n","  -1.81667539e-01  4.77436389e-02  1.18594863e-01  4.84766344e-04\n","  -1.29792313e-01  1.18936144e-01 -1.71270738e-01  5.56919060e-03\n","   1.65491575e-01 -3.12932060e-01  2.95001935e-02  1.65718342e-01\n","  -3.00568579e-02 -3.45425095e-02 -4.16284969e-02  1.56017408e-01\n","  -1.76572133e-01  6.67617772e-02 -3.51348897e-01 -3.14830505e-01\n","  -3.29884077e-02  6.38196237e-01  4.68969059e-02  2.31011449e-02\n","   1.64281673e-02 -1.93791818e-02]\n"," [-1.31807842e-01 -9.33067601e-02 -8.16973215e-02 -2.89774779e-01\n","  -1.25217424e-01  1.31508451e-01  3.56779981e-01  7.73552117e-02\n","  -3.39743954e-01 -2.99164651e-02  3.85635160e-01  6.75400952e-02\n","   8.33068171e-02 -1.42096341e-01 -2.26057153e-01  2.69391281e-01\n","  -1.70546949e-01  2.85740175e-01 -1.07687641e-02  5.65205199e-02\n","   3.40652439e-01  1.07062781e-01  1.38061999e-01 -4.07083805e-03\n","   6.07879350e-02 -1.71193260e-01  1.58512499e-02 -4.81881179e-02\n","  -1.99388591e-02 -4.83189460e-03]\n"," [-2.29071038e-02 -1.51244737e-01 -1.69852358e-01 -2.92434787e-01\n","   1.47893662e-01 -4.13031760e-01  9.98722799e-02  3.18753060e-01\n","   3.86577434e-01 -6.28021990e-02  9.53482403e-02 -3.87532297e-01\n","   1.36034104e-01 -6.94701672e-02 -1.66222471e-01 -5.58904764e-02\n","   2.39348339e-01 -1.10734110e-01 -1.32437490e-01 -2.17579112e-01\n","   1.53940696e-01  1.44911128e-01 -7.81637195e-02 -7.01462887e-02\n","  -4.36984319e-03  1.56525671e-02  2.94045420e-02 -1.05386452e-03\n","  -1.24832428e-02 -1.96449619e-04]\n"," [-5.21653607e-02 -1.71441804e-01 -9.39374958e-02 -1.90716551e-01\n","  -1.64491578e-01  9.54265046e-02 -1.29757889e-01 -8.79289131e-03\n","  -4.65811195e-02 -1.06428539e-01 -2.60789834e-02  2.41576730e-01\n","   3.65142631e-01 -2.68404850e-01  1.06104723e-01 -4.09749106e-01\n","   1.76021975e-01  3.11769132e-02 -2.74791250e-01  1.29085126e-02\n","  -2.56309704e-01  6.34998066e-02  1.50250071e-01  1.72760255e-01\n","   4.02390284e-01 -1.37384844e-01  2.30611278e-03  3.95482947e-02\n","  -1.89664302e-02  7.06187442e-03]\n"," [-2.49467377e-01  2.45894382e-01  4.73306015e-02  1.32837787e-02\n","   6.42742039e-02 -2.10480465e-02 -1.47176126e-01  8.08860497e-02\n","   1.75748899e-02 -1.55595908e-02  1.89551726e-02  1.16767653e-01\n","   1.05773629e-01 -8.83814503e-02 -2.95922771e-03  8.16921712e-02\n","  -1.65012312e-02 -1.66957050e-01 -3.31408503e-01  1.68680436e-01\n","   1.32799612e-01 -2.05023007e-01  1.07599636e-02 -1.82370508e-01\n","  -1.96451401e-01 -1.39606479e-01  1.25573527e-01  3.78939093e-01\n","  -5.55135704e-01 -1.29546156e-01]\n"," [-1.14379808e-01  4.34032305e-02 -5.68967368e-01  4.18279914e-01\n","   7.06854725e-02  2.05638609e-02  1.24214915e-02 -9.74694467e-03\n","  -3.77024794e-02  3.21505079e-02  3.64587215e-02  4.92654354e-02\n","   4.86674157e-02 -1.14199686e-01  2.53897332e-01  1.37472523e-01\n","  -2.23893713e-01  4.49950395e-02 -1.64835284e-01 -5.26927220e-01\n","   9.57809928e-03  8.10000234e-02 -2.71068920e-02 -7.93398994e-02\n","   5.53542588e-02 -1.96904348e-02 -3.77073376e-02  1.19597961e-02\n","   4.83686532e-03  6.55443983e-04]\n"," [-2.50925013e-01  2.14825927e-01  3.94265576e-02  5.15644594e-03\n","   3.41489479e-02 -2.53735475e-02 -1.42827557e-01  7.25170767e-02\n","   2.00294998e-02 -9.76897421e-03  2.04644779e-02  7.88321250e-02\n","   2.45761942e-02 -4.03230248e-02 -1.32783540e-02  1.68519525e-01\n","   3.21246972e-02 -1.11309527e-01 -2.75801694e-01  5.12495150e-02\n","   9.84510067e-02 -1.86069545e-01 -1.67412737e-01  3.31299191e-01\n","   3.72247215e-02  8.14039533e-02  2.44038312e-01 -6.87496742e-01\n","   4.38397281e-02  8.68665446e-02]\n"," [-1.96843139e-01  1.98613768e-01  2.59930609e-02 -1.87200733e-02\n","   8.29556387e-02  4.64568224e-03 -2.21332397e-01  8.79356053e-02\n","  -3.00728927e-02  5.34620057e-02 -4.69439195e-02  5.09514653e-02\n","   1.25176072e-01 -3.31847496e-02  4.36149703e-02  1.12706289e-01\n","  -1.12838232e-01 -3.94334840e-01 -5.40523768e-02  1.95781371e-01\n","   2.88097506e-01  3.24080079e-01  1.58335449e-01  7.44575013e-02\n","   6.19168240e-02  5.26295357e-02 -2.44322467e-01  2.36786594e-01\n","   5.15002693e-01  3.87106592e-02]\n"," [-1.25389964e-01 -2.32464004e-01  1.60888951e-01  2.94860086e-01\n","   4.03681194e-01  2.93417552e-01  7.06789708e-02  3.21787438e-01\n","  -1.28105559e-02  5.44697319e-02 -1.11363317e-01  9.74450869e-02\n","   3.43711691e-02 -1.62870482e-01  1.76028302e-01  1.20916045e-01\n","   5.17643008e-01  2.01118413e-01  1.22602922e-01  6.55807519e-02\n","   1.70915427e-01  3.37583037e-02  1.86589943e-02 -4.53484036e-02\n","   2.89858226e-02  5.29901520e-03  7.48320446e-03 -1.06887045e-03\n","   4.55943783e-03  5.84136525e-03]\n"," [-2.04622936e-01 -1.81469090e-01  3.01382991e-02  2.03861631e-01\n","  -2.44836372e-01 -9.17183083e-02 -1.63686937e-01  1.83194079e-01\n","   1.16938922e-01 -3.15826946e-02  6.24658650e-02  1.14463142e-01\n","  -4.14973800e-01  1.22338068e-01 -1.35650932e-01 -4.72302837e-02\n","  -8.99596451e-02  3.62063120e-02 -1.63735801e-02  1.52304707e-01\n","   9.87701732e-02  1.33453072e-01 -3.51550931e-01 -2.30314117e-01\n","   5.06652421e-01 -1.14248887e-01  6.92456777e-02  5.00182783e-02\n","  -1.65552938e-02 -1.24710915e-02]\n"," [-2.60366843e-01 -1.37043699e-01  2.80610830e-02  1.68147607e-01\n","  -3.05305964e-01 -1.93414328e-02  1.03578149e-01  4.77182112e-02\n","   1.26876252e-02  3.93685199e-01 -3.51680643e-01 -1.11836082e-01\n","  -5.48687948e-02 -6.66015405e-02 -3.99412377e-01  7.19995308e-02\n","   6.06451638e-02 -1.32538720e-01  5.27198984e-03 -1.59263342e-01\n","  -4.34457267e-02 -2.07434284e-01  4.66152914e-01  1.20626708e-02\n","   6.78214602e-02  1.72682097e-02  4.79039760e-03 -1.76329335e-02\n","  -7.08237428e-03 -4.43000181e-04]\n"," [-3.65920032e-01 -2.78371874e-02  1.42612887e-01  1.72387276e-01\n","  -7.31503026e-02  3.48354886e-02  3.35701250e-01  1.05967999e-01\n","  -1.11589291e-01  1.09829037e-01  4.59804386e-01  1.41885579e-02\n","   1.49395871e-01  3.00706545e-01  4.77344669e-02 -1.42968184e-01\n","   1.21316507e-01 -3.29956188e-01  5.87587778e-02 -6.30790579e-02\n","  -3.64148668e-01  7.14776664e-02 -1.45278169e-01  5.15703318e-02\n","  -1.29463027e-01 -1.15830588e-02 -5.12606123e-02  2.71990389e-02\n","   2.05380633e-02 -1.33772287e-03]\n"," [-9.88832509e-02 -1.48091441e-01  5.35618313e-02  1.78088375e-01\n","   1.21733548e-01 -5.41796686e-01  2.98982970e-02  2.52059449e-01\n","   3.64423909e-02  5.76667116e-02  2.07268058e-02  1.89952910e-02\n","   1.85624883e-01 -1.37889344e-01  2.12754142e-01  4.50805514e-02\n","  -3.94249466e-01  2.38549799e-01  1.72866801e-01  3.32330488e-01\n","  -1.99080773e-01 -1.57677478e-01  1.46569222e-01  1.19615778e-01\n","   3.35012837e-04 -2.45539104e-02 -2.07634521e-02 -8.75181447e-03\n","   2.53716891e-02  3.89002065e-04]\n"," [-9.64369144e-02 -2.57088275e-01  3.49384781e-02  1.79933309e-01\n","  -1.46601351e-01  3.16622552e-02 -3.46609482e-01  5.05623483e-02\n","   3.94883040e-02 -4.58298762e-03  5.29163711e-02  1.75177507e-01\n","   2.25788770e-01  1.21188586e-01 -2.89557920e-01 -3.24620818e-01\n","  -1.06945513e-01  2.80179584e-01 -3.09482093e-02 -9.35961325e-02\n","   2.45888469e-01  1.31389777e-01 -8.60828319e-02  8.07000367e-02\n","  -4.72822350e-01  1.95224794e-01 -4.41295157e-02 -2.53799846e-02\n","   1.71164562e-02  1.00616827e-03]]\n","\n"," the fraction of total variances:\n"," [0.5349571975270809, 0.16787348900639723, 0.07024212689771496, 0.06480403980842372, 0.04189457582662958, 0.03112359840565237, 0.015698781063078517, 0.011889865098416726, 0.010769379456249223, 0.009527096420780376, 0.008721349374274379, 0.007383726495221651, 0.006682674660101146, 0.004727164714065854, 0.002476421645326321, 0.0023166203941971625, 0.001494399633841048, 0.0014737212158842444, 0.0012548215574052233, 0.0009422023989287915, 0.0009137707924211519, 0.0008244146512390448, 0.0005275612801011055, 0.000494296598839036, 0.00042541468386505317, 0.00030500994747923355, 0.00016657834875953087, 5.9496993191180056e-05, 2.4224584446846415e-05, 5.980519988530665e-06]\n","\n"," the cumulative sum:\n"," [0.5349572  0.70283069 0.77307281 0.83787685 0.87977143 0.91089503\n"," 0.92659381 0.93848367 0.94925305 0.95878015 0.9675015  0.97488523\n"," 0.9815679  0.98629506 0.98877149 0.99108811 0.99258251 0.99405623\n"," 0.99531105 0.99625325 0.99716702 0.99799144 0.998519   0.99901329\n"," 0.99943871 0.99974372 0.9999103  0.99996979 0.99999402 1.        ]\n","\n"," item is:\n"," 0.9587801495104237\n","\n"," we take till index: \n"," 9\n","\n"," the projection matrix is:\n"," [[-2.41851937e-01  2.70653449e-01  4.75474395e-02 -5.48239712e-02\n","   9.25795485e-03 -2.08998201e-02  3.34221197e-02 -5.01874316e-02\n","   1.70487994e-01]\n"," [-1.00106853e-01  6.70947377e-02 -5.48417835e-01  2.37597187e-01\n","   2.34996616e-02  2.86496334e-02  1.14146219e-02 -6.53118295e-02\n","  -2.17331564e-01]\n"," [-2.47161360e-01  2.42223300e-01  4.41503410e-02 -5.88361688e-02\n","   3.49397309e-03 -1.85775402e-02  2.30952916e-02 -6.59039166e-02\n","   1.71837984e-01]\n"," [-2.07163436e-01  2.29192811e-01  2.88524539e-02 -7.71652887e-02\n","   4.23136571e-02  3.31815978e-04 -5.55779028e-02 -1.57144568e-02\n","   1.15601730e-01]\n"," [-1.23867832e-01 -2.38364092e-01  1.47651938e-01  2.98631272e-02\n","   4.35120786e-01  2.18298989e-01  4.76044257e-02 -1.97494914e-01\n","   9.17017793e-02]\n"," [-2.41742153e-01 -2.05497205e-01  3.07992486e-02 -4.02426933e-02\n","  -5.07962254e-02 -4.66908516e-04 -1.00519318e-01 -1.75250368e-01\n","   1.43552343e-01]\n"," [-2.99956305e-01 -9.86520273e-02 -1.63553857e-02 -1.11114133e-01\n","  -1.16005523e-01  6.31619189e-02  1.39552942e-01 -2.32639102e-01\n","   4.55758258e-02]\n"," [-3.18644522e-01  1.11526089e-02  6.40975017e-02 -8.24032843e-02\n","   1.00248480e-01  7.12045665e-02  1.71354386e-01 -2.32879144e-01\n","   1.08668438e-01]\n"," [-1.18655912e-01 -2.11394959e-01  1.50856721e-02 -7.80758081e-02\n","   2.85537590e-01 -5.09229978e-01  7.92699113e-02 -3.34263575e-01\n","  -4.27557350e-01]\n"," [-4.87010926e-02 -4.09459391e-01  9.60035526e-03 -4.81138878e-02\n","   2.43867496e-02  1.12206758e-01 -3.86244590e-01 -2.38761767e-01\n","   5.39795791e-02]\n"," [-1.32414383e-01  6.74495724e-02 -7.80288556e-02 -2.23106433e-01\n","   1.65000962e-01  2.82159869e-02 -2.91391466e-01  1.30043147e-01\n","  -2.62533746e-01]\n"," [-5.51292527e-03 -7.12463919e-02 -4.33018458e-01 -1.77512576e-01\n","   1.82514607e-01  6.98438672e-02  6.11073241e-02 -1.88088546e-01\n","   4.33559938e-01]\n"," [-1.34861705e-01  5.20810415e-02 -8.79142306e-02 -2.23578504e-01\n","   1.16380765e-01  1.15687369e-02 -2.70173488e-01  1.17067296e-01\n","  -2.27142763e-01]\n"," [-9.77518660e-02  7.52996544e-02 -3.31748830e-02 -1.26992223e-01\n","   9.78619223e-02  2.41634681e-02 -2.31763435e-01  8.50523751e-02\n","  -1.63726752e-01]\n"," [-1.31270565e-03 -1.34192899e-01 -1.12574475e-01 -2.05951536e-01\n","   2.19079278e-01  2.67939452e-01  1.60762790e-01  4.26376809e-01\n","  -1.50974984e-02]\n"," [-1.40212984e-01 -2.05328613e-01 -1.50356803e-01 -2.41213736e-01\n","  -3.09510155e-01  1.21389086e-02 -4.05274982e-02  2.06865229e-01\n","   2.00411769e-02]\n"," [-6.90262379e-02 -9.02731190e-02 -6.70459336e-02 -1.45289223e-01\n","  -1.81667539e-01  4.77436389e-02  1.18594863e-01  4.84766344e-04\n","  -1.29792313e-01]\n"," [-1.31807842e-01 -9.33067601e-02 -8.16973215e-02 -2.89774779e-01\n","  -1.25217424e-01  1.31508451e-01  3.56779981e-01  7.73552117e-02\n","  -3.39743954e-01]\n"," [-2.29071038e-02 -1.51244737e-01 -1.69852358e-01 -2.92434787e-01\n","   1.47893662e-01 -4.13031760e-01  9.98722799e-02  3.18753060e-01\n","   3.86577434e-01]\n"," [-5.21653607e-02 -1.71441804e-01 -9.39374958e-02 -1.90716551e-01\n","  -1.64491578e-01  9.54265046e-02 -1.29757889e-01 -8.79289131e-03\n","  -4.65811195e-02]\n"," [-2.49467377e-01  2.45894382e-01  4.73306015e-02  1.32837787e-02\n","   6.42742039e-02 -2.10480465e-02 -1.47176126e-01  8.08860497e-02\n","   1.75748899e-02]\n"," [-1.14379808e-01  4.34032305e-02 -5.68967368e-01  4.18279914e-01\n","   7.06854725e-02  2.05638609e-02  1.24214915e-02 -9.74694467e-03\n","  -3.77024794e-02]\n"," [-2.50925013e-01  2.14825927e-01  3.94265576e-02  5.15644594e-03\n","   3.41489479e-02 -2.53735475e-02 -1.42827557e-01  7.25170767e-02\n","   2.00294998e-02]\n"," [-1.96843139e-01  1.98613768e-01  2.59930609e-02 -1.87200733e-02\n","   8.29556387e-02  4.64568224e-03 -2.21332397e-01  8.79356053e-02\n","  -3.00728927e-02]\n"," [-1.25389964e-01 -2.32464004e-01  1.60888951e-01  2.94860086e-01\n","   4.03681194e-01  2.93417552e-01  7.06789708e-02  3.21787438e-01\n","  -1.28105559e-02]\n"," [-2.04622936e-01 -1.81469090e-01  3.01382991e-02  2.03861631e-01\n","  -2.44836372e-01 -9.17183083e-02 -1.63686937e-01  1.83194079e-01\n","   1.16938922e-01]\n"," [-2.60366843e-01 -1.37043699e-01  2.80610830e-02  1.68147607e-01\n","  -3.05305964e-01 -1.93414328e-02  1.03578149e-01  4.77182112e-02\n","   1.26876252e-02]\n"," [-3.65920032e-01 -2.78371874e-02  1.42612887e-01  1.72387276e-01\n","  -7.31503026e-02  3.48354886e-02  3.35701250e-01  1.05967999e-01\n","  -1.11589291e-01]\n"," [-9.88832509e-02 -1.48091441e-01  5.35618313e-02  1.78088375e-01\n","   1.21733548e-01 -5.41796686e-01  2.98982970e-02  2.52059449e-01\n","   3.64423909e-02]\n"," [-9.64369144e-02 -2.57088275e-01  3.49384781e-02  1.79933309e-01\n","  -1.46601351e-01  3.16622552e-02 -3.46609482e-01  5.05623483e-02\n","   3.94883040e-02]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJz4yVo6MZ4V","executionInfo":{"status":"ok","timestamp":1608634088663,"user_tz":-120,"elapsed":675,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"181cf794-d76a-40a4-ba18-8379c9a67c3e"},"source":["# Project the training set and test sets\r\n","P_train = np.dot(normalized_X_train, U)\r\n","print(\"\\n the projection of train is:\\n\", P_train)\r\n","print(P_train.shape)\r\n","\r\n","P_test = np.dot(normalized_X_test, U)\r\n","print(\"\\n the projection of test is:\\n\", P_test)\r\n","print(P_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," the projection of train is:\n"," [[-1.52560331e+00 -4.22089760e-01 -1.55896660e-01 ...  5.70334515e-02\n","   1.22696395e-01  1.60343013e-03]\n"," [-1.90072326e+00 -6.84639268e-01 -2.20038129e-01 ...  7.82321147e-02\n","   3.08246422e-02 -4.06833949e-02]\n"," [-8.47346089e-01 -1.23688034e-01 -4.74958094e-02 ... -5.16677337e-02\n","   3.42671378e-02 -7.74586543e-03]\n"," ...\n"," [-1.41019246e+00 -1.33298250e-01 -2.57159532e-01 ... -7.90567124e-02\n","   5.25612185e-02 -8.36384973e-03]\n"," [-7.50832288e-01 -4.06124685e-02 -2.10044132e-01 ... -5.91466681e-02\n","   1.36396680e-02  2.34762948e-02]\n"," [-9.07465297e-01 -1.73015062e-01 -3.20311124e-01 ...  6.71929715e-02\n","   9.34015006e-03 -2.50351083e-04]]\n","(455, 9)\n","\n"," the projection of test is:\n"," [[-2.73230538  0.65312034 -0.33851248 ... -0.5521519   0.26640795\n","  -0.05933155]\n"," [-0.74602891 -0.27674974 -0.16394341 ...  0.1123441   0.00306498\n","  -0.01070598]\n"," [-0.64540641 -0.43257133 -0.48824819 ...  0.07319151  0.20626567\n","   0.15504923]\n"," ...\n"," [-1.17407878 -0.52655165 -0.19552911 ... -0.10977672 -0.04887734\n","   0.05455001]\n"," [-1.10198103  0.17037608 -0.4874641  ...  0.0180871  -0.03460355\n","   0.03276914]\n"," [-1.28638775 -0.79522264 -0.29323395 ...  0.11657626  0.11100594\n","  -0.03706497]]\n","(114, 9)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rIPpeU_v2U2X"},"source":["#**Results** "]},{"cell_type":"code","metadata":{"id":"HyMHSA6jrG50","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608634093235,"user_tz":-120,"elapsed":1604,"user":{"displayName":"Arsany Atef","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnWLay54uiaokBHn8Qu6mcClJn-2QDu363_aYQcQ=s64","userId":"18018075603714929228"}},"outputId":"99f783ce-9db2-4727-90c8-9c6bd2bfa945"},"source":["print(\"\\nResults after Projection\\n________________________\")\r\n","classifier(P_train, y_train, P_test, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Results after Projection\n","________________________\n","# Tuning hyper-parameters for precision\n","Best parameter \"C value\"  is {'C': 10}\n","\n","Grid scores for all C values :\n","\n","0.849 (+/-0.022) for {'C': 0.01}\n","0.949 (+/-0.021) for {'C': 0.1}\n","0.974 (+/-0.021) for {'C': 1}\n","0.981 (+/-0.017) for {'C': 10}\n","0.980 (+/-0.027) for {'C': 100}\n","0.977 (+/-0.028) for {'C': 1000}\n","\n","Evaluation:\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.99      0.97        72\n","           1       0.97      0.93      0.95        42\n","\n","    accuracy                           0.96       114\n","   macro avg       0.97      0.96      0.96       114\n","weighted avg       0.97      0.96      0.96       114\n","\n","_______________________________________________________________________________________\n","# Tuning hyper-parameters for recall\n","Best parameter \"C value\"  is {'C': 100}\n","\n","Grid scores for all C values :\n","\n","0.635 (+/-0.073) for {'C': 0.01}\n","0.914 (+/-0.052) for {'C': 0.1}\n","0.961 (+/-0.026) for {'C': 1}\n","0.973 (+/-0.035) for {'C': 10}\n","0.974 (+/-0.041) for {'C': 100}\n","0.972 (+/-0.042) for {'C': 1000}\n","\n","Evaluation:\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.96      0.96        72\n","           1       0.93      0.93      0.93        42\n","\n","    accuracy                           0.95       114\n","   macro avg       0.94      0.94      0.94       114\n","weighted avg       0.95      0.95      0.95       114\n","\n","_______________________________________________________________________________________\n","# Tuning hyper-parameters for f1\n","Best parameter \"C value\"  is {'C': 100}\n","\n","Grid scores for all C values :\n","\n","0.621 (+/-0.100) for {'C': 0.01}\n","0.927 (+/-0.044) for {'C': 0.1}\n","0.967 (+/-0.023) for {'C': 1}\n","0.976 (+/-0.027) for {'C': 10}\n","0.976 (+/-0.034) for {'C': 100}\n","0.974 (+/-0.035) for {'C': 1000}\n","\n","Evaluation:\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.96      0.96        72\n","           1       0.93      0.93      0.93        42\n","\n","    accuracy                           0.95       114\n","   macro avg       0.94      0.94      0.94       114\n","weighted avg       0.95      0.95      0.95       114\n","\n","_______________________________________________________________________________________\n"],"name":"stdout"}]}]}